import streamlit as st
import feedparser
import pandas as pd
from datetime import datetime
import urllib.parse

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="å°è‚¡é¡ŒææŒ–æ˜æ©Ÿ (Googleå¼•æ“ç‰ˆ)",
    page_icon="ğŸ”¥",
    layout="wide",
)

# --- CSS å„ªåŒ– ---
st.markdown("""
    <style>
    .big-font { font-size:18px !important; }
    div[data-testid="stDataFrame"] { width: 100%; }
    </style>
    """, unsafe_allow_html=True)

# --- é—œéµå­—èˆ‡é è¨­è¨­å®š ---
# é€™è£¡å°‡é—œéµå­—åˆ†é¡ï¼Œæ–¹ä¾¿ä½¿ç”¨è€…ä¸€æ¬¡é¸ä¸€çµ„
KEYWORD_GROUPS = {
    'ğŸ”¥ ç†±é–€é¡Œæ': ['æ”¶è³¼', 'ä½µè³¼', 'å…¥è‚¡', 'è™•åˆ†åˆ©ç›Š', 'ç¶“ç‡Ÿæ¬Š'],
    'ğŸ’° ç‡Ÿæ”¶ç²åˆ©': ['è¨‚å–®', 'å¤§å–®', 'æ€¥å–®', 'è½‰å–®', 'ç‡Ÿæ”¶æ–°é«˜', 'ç²åˆ©æ–°é«˜', 'ä¸‰ç‡ä¸‰å‡'],
    'ğŸ­ ç”¢æ¥­å‹•æ…‹': ['æ¼²åƒ¹', 'èª¿æ¼²', 'å ±åƒ¹', 'æ“´ç”¢', 'æ–°å» ', 'ç¼ºè²¨', 'ä¾›ä¸æ‡‰æ±‚'],
    'ğŸ“ˆ è‚¡å¸‚è¨Šè™Ÿ': ['æ³•èªª', 'åº«è—è‚¡', 'å¯¦æ–½åº«è—', 'å¢è³‡', 'æ¸›è³‡', 'è‚¡åˆ©', 'æ®–åˆ©ç‡'],
    'ğŸ¤– ç§‘æŠ€è¶¨å‹¢': ['AI', 'ä¼ºæœå™¨', 'CPO', 'æ•£ç†±', 'æ©Ÿå™¨äºº', 'CoWoS', 'å…ˆé€²å°è£']
}

# æŒ‡å®šæœå°‹çš„æ–°èä¾†æº (é¿å…æœå°‹åˆ°éƒ¨è½æ ¼æˆ–å…§å®¹è¾²å ´)
TARGET_SITES = [
    'site:news.cnyes.com',       # é‰…äº¨ç¶²
    'site:money.udn.com',        # ç¶“æ¿Ÿæ—¥å ±
    'site:tw.stock.yahoo.com',   # Yahooè‚¡å¸‚
    'site:ctee.com.tw',          # å·¥å•†æ™‚å ±
    'site:bnext.com.tw',         # æ•¸ä½æ™‚ä»£
    'site:technews.tw'           # ç§‘æŠ€æ–°å ±
]

def get_google_news_feed(keywords):
    """
    å»ºç«‹ Google News RSS æœå°‹é€£çµ
    """
    # çµ„åˆé—œéµå­—æŸ¥è©¢ï¼š(é—œéµå­—1 OR é—œéµå­—2)
    kw_query = " OR ".join(keywords)
    
    # çµ„åˆç¶²ç«™ä¾†æºæŸ¥è©¢ï¼š(site:A OR site:B)
    site_query = " OR ".join(TARGET_SITES)
    
    # æœ€çµ‚æŸ¥è©¢å­—ä¸²ï¼š(è¨‚å–® OR å¤§å–®) AND (site:cnyes... OR ...) when:1d
    # when:1d ä»£è¡¨åªæœå°‹éå» 24 å°æ™‚ (ç¢ºä¿æ–°èæ–°é®®)
    full_query = f"({kw_query}) AND ({site_query}) when:1d"
    
    # é€²è¡Œ URL ç·¨ç¢¼
    encoded_query = urllib.parse.quote(full_query)
    
    # Google News RSS æ ¼å¼
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    return rss_url

def fetch_google_news(keywords):
    if not keywords:
        return []
    
    rss_url = get_google_news_feed(keywords)
    
    try:
        feed = feedparser.parse(rss_url)
        news_items = []
        
        for entry in feed.entries:
            # è™•ç†æ™‚é–“æ ¼å¼
            pub_date = entry.published if 'published' in entry else ""
            try:
                # å˜—è©¦å°‡ Google æ™‚é–“è½‰ç‚º datetime ç‰©ä»¶ä»¥ä¾¿æ’åº
                dt_obj = pd.to_datetime(pub_date)
                display_time = dt_obj.strftime("%m-%d %H:%M")
            except:
                display_time = pub_date

            news_items.append({
                'æ™‚é–“': display_time,
                'æ¨™é¡Œ': entry.title,
                'é€£çµ': entry.link,
                'ä¾†æºæ©Ÿæ§‹': entry.source.title if 'source' in entry else "Google News",
                'åŸå§‹æ™‚é–“': dt_obj if 'dt_obj' in locals() else datetime.min # ç”¨æ–¼æ’åº
            })
            
        return news_items
    except Exception as e:
        st.error(f"é€£ç·šç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

# --- å´é‚Šæ¬„æ§åˆ¶ ---
st.sidebar.header("ğŸ” æœå°‹è¨­å®š")

# é¸æ“‡é¡Œæç¾¤çµ„
selected_group = st.sidebar.selectbox("é¸æ“‡é¡Œæé¡å‹", list(KEYWORD_GROUPS.keys()))
default_kws = KEYWORD_GROUPS[selected_group]

# å…è¨±ä½¿ç”¨è€…å¢åˆªé—œéµå­—
user_keywords = st.sidebar.multiselect(
    "ç´°éƒ¨èª¿æ•´é—œéµå­—",
    options=default_kws + ['å°ç©é›»', 'é´»æµ·', 'è¯ç™¼ç§‘'], # è£œå……ä¸€äº›å€‹è‚¡ä¾›é¸
    default=default_kws
)

# è‡ªå®šç¾©è¼¸å…¥
custom_kw = st.sidebar.text_input("æˆ–è¼¸å…¥è‡ªè¨‚é—œéµå­— (å¦‚ï¼šB100)")
if custom_kw:
    user_keywords.append(custom_kw)

if st.sidebar.button("ğŸš€ é–‹å§‹æœå°‹", type="primary"):
    st.session_state['trigger_search'] = True

# --- ä¸»ç•«é¢ ---
st.title(f"ğŸ“° å°è‚¡æ–°èå¿«æœï¼š{selected_group}")
st.caption("è³‡æ–™ä¾†æºï¼šGoogle News (é–å®šé‰…äº¨ã€è¯åˆã€å·¥å•†ã€Yahooç­‰æ¬Šå¨åª’é«”)")

# è‡ªå‹•è§¸ç™¼æˆ–æ‰‹å‹•è§¸ç™¼
if user_keywords:
    with st.spinner('æ­£åœ¨å¬å–š Google æœå°‹å¼•æ“...'):
        data = fetch_google_news(user_keywords)
        
    if data:
        df = pd.DataFrame(data)
        # ä¾ç…§æ™‚é–“æ’åº (æ–°çš„åœ¨ä¸Šé¢)
        df = df.sort_values(by='åŸå§‹æ™‚é–“', ascending=False)
        
        # é¡¯ç¤ºçµæœ
        st.success(f"éå» 24 å°æ™‚å…§ï¼Œæ‰¾åˆ° **{len(df)}** å‰‡ç›¸é—œæ–°è")
        
        st.dataframe(
            df[['æ™‚é–“', 'ä¾†æºæ©Ÿæ§‹', 'æ¨™é¡Œ', 'é€£çµ']],
            column_config={
                "é€£çµ": st.column_config.LinkColumn("æ–°èé€£çµ", display_text="å‰å¾€é–±è®€"),
                "æ¨™é¡Œ": st.column_config.TextColumn("æ¨™é¡Œ", width="large"),
            },
            hide_index=True,
            use_container_width=True
        )
    else:
        st.warning("ğŸ§ éå» 24 å°æ™‚å…§ï¼Œä¸»è¦åª’é«”æ²’æœ‰å ±å°åŒ…å«é€™äº›é—œéµå­—çš„æ–°èã€‚")
        st.info("å»ºè­°ï¼šå˜—è©¦æ›´æ›ã€Œé¡Œæé¡å‹ã€æˆ–æ˜¯å¢åŠ æ›´é€šç”¨çš„é—œéµå­—ã€‚")
else:
    st.info("ğŸ‘ˆ è«‹åœ¨å·¦å´é¸æ“‡é—œéµå­—é–‹å§‹æœå°‹")
